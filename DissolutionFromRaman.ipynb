{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zoN8R4FdpU1_F6l5elccLReYOvt8Cfse",
      "authorship_tag": "ABX9TyP0Rj/FtVhDLxi0bVMRuyYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CsonVass/raman/blob/main/DissolutionFromRaman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "z9yEcW6Rjf8m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "# device_lib.list_local_devices()"
      ],
      "metadata": {
        "id": "JG9BvdDuk98G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "tL_UdCLKljRO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "!pip install -q scikit-learn==0.23.1"
      ],
      "metadata": {
        "id": "udUYhHFkmcQ9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dLSRMq_gmlfT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hpmcMaps = []\n",
        "# dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Raman/hpmc/c/DR_C01A-component-2.csv', header=None)\n"
      ],
      "metadata": {
        "id": "6_L31i1jm3i8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_curve_pairs = {}\n",
        "missing = []\n",
        "path_to_hpmc_c = '/content/drive/MyDrive/Colab Notebooks/Raman/hpmc/c'\n",
        "path_to_hpmc_v = '/content/drive/MyDrive/Colab Notebooks/Raman/hpmc/v'\n",
        "\n",
        "paths = [path_to_hpmc_c, path_to_hpmc_v]\n",
        "\n",
        "for path in paths:\n",
        "  dir_list = os.listdir(path)\n",
        "  for f in dir_list: \n",
        "    path_to_map = path + '/' + f\n",
        "    map_name = f.split('-')[0].split('_')[1]\n",
        "    map_curve_pairs[map_name] = {}\n",
        "    map_csv = pd.read_csv(path_to_map, header=None)\n",
        "    if len(map_csv.index) == 1:\n",
        "      tmp = []\n",
        "      for i in range(0, 31*31, 31):\n",
        "        tmp.append([map_csv.iloc[0:1, i:i+31].values])\n",
        "      map_csv = pd.DataFrame(tmp)\n",
        "    map_curve_pairs[map_name]['map'] = map_csv\n",
        "\n",
        "dissolutionCureves = []\n",
        "curves_csv = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Raman/Tablettak_minden_adat.csv', header=None)\n",
        "names = curves_csv.iloc[0:1, 1:]\n",
        "time = curves_csv.iloc[4:,0:1]\n",
        "curve_points = curves_csv.iloc[4:,1:].apply(lambda x: x.str.replace(',','.'))\n",
        "for i in range(len(curve_points.columns)):\n",
        "    curve_i = curve_points.iloc[:, i:i+1]\n",
        "    if(names.iloc[0,i] in map_curve_pairs):\n",
        "      map_curve_pairs[names.iloc[0,i]]['curve'] = np.asarray((curve_i).T).astype(np.float32)\n",
        "    else: \n",
        "      missing.append(names.iloc[0,i])\n",
        "\n",
        "mcp_cpy = map_curve_pairs.copy()\n",
        "for name in mcp_cpy:\n",
        "  if not 'curve' in map_curve_pairs[name] or len(map_curve_pairs[name]['map']) != 31:\n",
        "    missing.append(map_curve_pairs[name])\n",
        "    map_curve_pairs.pop(name)  "
      ],
      "metadata": {
        "id": "TAROz5M6d2Ff"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "keys = []\n",
        "\n",
        "for key in sorted(map_curve_pairs):\n",
        " x.append(np.asarray(map_curve_pairs[key]['map']).flatten())\n",
        " y.append(np.asarray(map_curve_pairs[key]['curve']))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "x_train = x_train.reshape(105, -1)\n",
        "\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "y_train = y_train.reshape(105, -1)"
      ],
      "metadata": {
        "id": "lbsMp93fQQnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c58d1d-16b0-46af-95fa-a48f58b0efdd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.nn_ops import softmax\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(37, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True), \n",
        "              metrics = [tf.keras.metrics.Accuracy()])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=3)"
      ],
      "metadata": {
        "id": "59OBR5ZHiNc_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "9902b342-18e3-4975-97d7-50a890c5df2e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-f1120d7dd655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m               metrics = [tf.keras.metrics.Accuracy()])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    }
  ]
}